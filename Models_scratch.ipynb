{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd5c2a6c",
   "metadata": {},
   "source": [
    "# Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75ceab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e35453d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"./10000/\"\n",
    "\n",
    "X = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b19ca24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (10000, 784)\n",
      "y shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for label in range(10):\n",
    "    folder_path = os.path.join(root_dir, str(label))\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "\n",
    "          \n",
    "            img = Image.open(img_path)\n",
    "            img = img.convert(\"L\")\n",
    "            img = img.resize((28, 28))\n",
    "            img_array = np.array(img)\n",
    "            img_flat = img_array.flatten()\n",
    "\n",
    "            X.append(img_flat)\n",
    "            y.append(label)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caeff01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (8000, 784)\n",
      "Test size: (2000, 784)\n"
     ]
    }
   ],
   "source": [
    "X = X / 255.0\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape)\n",
    "print(\"Test size:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84350c40",
   "metadata": {},
   "source": [
    "# Linear regression from scratch :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f401e9",
   "metadata": {},
   "source": [
    "## Model class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30ef4a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionGD:\n",
    "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.theta = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        X = np.c_[np.ones(n_samples), X]\n",
    "        self.theta = np.zeros(n_features + 1) \n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "         \n",
    "            y_pred = X.dot(self.theta)\n",
    "            error = y_pred - y\n",
    "            gradient = (2 / n_samples) * X.T.dot(error)\n",
    "            self.theta = self.theta - self.lr * gradient\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        X = np.c_[np.ones(n_samples), X]\n",
    "        return X.dot(self.theta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2994fe15",
   "metadata": {},
   "source": [
    "## Model Training and evluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0ddd50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6265\n",
      "Precision: 0.6719\n",
      "Recall: 0.6265\n",
      "F1-score: 0.6262\n",
      "\n",
      "Confusion Matrix:\n",
      "[[153  17   0   2  10   2   5   3   0   8]\n",
      " [  1 164   2   5   3   0  14   5   0   6]\n",
      " [  6  34  97  10   8   2  11  13   2  17]\n",
      " [ 14  13  11 132  13   2   0   2   3  10]\n",
      " [ 20  31   1   3 117   0  10   4   5   9]\n",
      " [ 11  14   1   3   7 133  21   3   4   3]\n",
      " [  4  23   0   1   0  12 157   0   3   0]\n",
      " [  1  60   0   1   9   2   8 101   1  17]\n",
      " [ 13  37   0  12  15  12  17  15  71   8]\n",
      " [ 11  16   1  12   9   0   0  22   1 128]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for digit in range(10):\n",
    "    y_binary = (y_train == digit).astype(int)\n",
    "    model = LinearRegressionGD(\n",
    "        learning_rate=0.0001,\n",
    "        epochs=1000\n",
    "    )\n",
    "    model.fit(X_train, y_binary)\n",
    "    models.append(model)\n",
    "scores = np.array([m.predict(X_test) for m in models])\n",
    "y_pred = np.argmax(scores, axis=0)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred,average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182ea0d6",
   "metadata": {},
   "source": [
    "## k_fold for Linear Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f32347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold accuracy: 0.5970\n",
      "Fold accuracy: 0.6050\n",
      "Fold accuracy: 0.6120\n",
      "Fold accuracy: 0.5655\n",
      "Fold accuracy: 0.6115\n",
      "Mean : 0.5982000000000001\n",
      "standard deviation : 0.017229625648864228\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kf_linear = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, test_idx in kf_linear.split(X):\n",
    "    X_train_fold, X_test_fold = X[train_idx], X[test_idx]\n",
    "    y_train_fold, y_test_fold = y[train_idx], y[test_idx]\n",
    "\n",
    "    models = []\n",
    "    for digit in range(10):\n",
    "        y_binary = (y_train_fold == digit).astype(int)\n",
    "        model = LinearRegressionGD(\n",
    "        learning_rate=0.0001,\n",
    "        epochs=1000\n",
    "                     )\n",
    "        model.fit(X_train_fold, y_binary)\n",
    "        models.append(model)\n",
    "\n",
    "   \n",
    "    scores = np.array([m.predict(X_test_fold) for m in models])\n",
    "    y_pred = np.argmax(scores, axis=0)\n",
    "\n",
    "\n",
    "    fold_acc = accuracy_score(y_test_fold, y_pred)\n",
    "    print(f\"Fold accuracy: {fold_acc:.4f}\")\n",
    "    cv_scores.append(fold_acc)\n",
    "\n",
    "print(\"Mean :\",np.mean(cv_scores))\n",
    "print(\"standard deviation :\",np.std(cv_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e50256",
   "metadata": {},
   "source": [
    "# Logistic regression from scratch :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb87487",
   "metadata": {},
   "source": [
    "## Model Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "09453cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionGD:\n",
    "    def __init__(self, learning_rate=0.01, epochs=1000):\n",
    "        self.lr = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.theta = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "  \n",
    "        z = np.clip(z, -500, 500)\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        X = np.c_[np.ones(n_samples), X]\n",
    "        self.theta = np.zeros(n_features + 1)\n",
    "\n",
    "        for _ in range(self.epochs):\n",
    "            z = X.dot(self.theta)\n",
    "            y_pred = self.sigmoid(z)\n",
    "            gradient = (1 / n_samples) * X.T.dot(y_pred - y)\n",
    "            self.theta -= self.lr * gradient\n",
    "\n",
    "    def predict(self, X):\n",
    "        X = np.c_[np.ones(X.shape[0]), X]\n",
    "        z = X.dot(self.theta)\n",
    "        return self.sigmoid(z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02ae42a",
   "metadata": {},
   "source": [
    "## Model Training and evluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f46c2ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7410\n",
      "Precision: 0.7427\n",
      "Recall: 0.7410\n",
      "F1-score: 0.7398\n",
      "\n",
      "Confusion Matrix:\n",
      "[[158  12   0   3   9   4   6   0   3   5]\n",
      " [  3 157   5   6   2   3   5  10   7   2]\n",
      " [  2   7 146  10   7   1   2   8   6  11]\n",
      " [  7   5   8 154  10   2   0   3   6   5]\n",
      " [  4  10   3   3 151   2   9   5   7   6]\n",
      " [  9   6   1   4   5 144  19   3   6   3]\n",
      " [  0  13   0   1   1  11 169   1   4   0]\n",
      " [  1  11   8   3   9   2   4 135   5  22]\n",
      " [ 11   9   4   7  12  17   9  13 114   4]\n",
      " [  5   2   4   8  12   0   0  13   2 154]]\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "for digit in range(10):\n",
    "    y_binary = (y_train == digit).astype(int)\n",
    "\n",
    "    model = LogisticRegressionGD(\n",
    "        learning_rate=0.1,\n",
    "        epochs=1000\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_binary)\n",
    "    models.append(model)\n",
    "scores = np.array([m.predict(X_test) for m in models])\n",
    "y_pred = np.argmax(scores, axis=0)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred,average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4397619",
   "metadata": {},
   "source": [
    "## k_fold for Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12e933b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold accuracy: 0.7310\n",
      "Fold accuracy: 0.7375\n",
      "Fold accuracy: 0.7240\n",
      "Fold accuracy: 0.7445\n",
      "Fold accuracy: 0.7400\n",
      "Mean : 0.7353999999999999\n",
      "standard deviation : 0.00717913643831905\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kf_linear = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, test_idx in kf_linear.split(X):\n",
    "    X_train_fold, X_test_fold = X[train_idx], X[test_idx]\n",
    "    y_train_fold, y_test_fold = y[train_idx], y[test_idx]\n",
    "\n",
    "    models = []\n",
    "    for digit in range(10):\n",
    "        y_binary = (y_train_fold == digit).astype(int)\n",
    "        model = LogisticRegressionGD(\n",
    "        learning_rate=0.1,\n",
    "        epochs=1000\n",
    "                     )\n",
    "        model.fit(X_train_fold, y_binary)\n",
    "        models.append(model)\n",
    "\n",
    "   \n",
    "    scores = np.array([m.predict(X_test_fold) for m in models])\n",
    "    y_pred = np.argmax(scores, axis=0)\n",
    "\n",
    "\n",
    "    fold_acc = accuracy_score(y_test_fold, y_pred)\n",
    "    print(f\"Fold accuracy: {fold_acc:.4f}\")\n",
    "    cv_scores.append(fold_acc)\n",
    "\n",
    "print(\"Mean :\",np.mean(cv_scores))\n",
    "print(\"standard deviation :\",np.std(cv_scores))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5669704",
   "metadata": {},
   "source": [
    "# Naive Bayes from scratch :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875b7df7",
   "metadata": {},
   "source": [
    "## Model Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67f8b4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class GaussianNaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        n_features = X.shape[1]\n",
    "\n",
    "        self.mean = {}\n",
    "        self.var = {}\n",
    "        self.prior = {}\n",
    "\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            self.mean[c] = X_c.mean(axis=0)\n",
    "            self.var[c] = X_c.var(axis=0) + 1e-9\n",
    "            self.prior[c] = X_c.shape[0] / X.shape[0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = []\n",
    "\n",
    "        for x in X:\n",
    "            posteriors = []\n",
    "\n",
    "            for c in self.classes:\n",
    "                log_prior = np.log(self.prior[c])\n",
    "                log_likelihood = -0.5 * np.sum(\n",
    "                    np.log(2 * np.pi * self.var[c]) +\n",
    "                    ((x - self.mean[c]) ** 2) / self.var[c]\n",
    "                )\n",
    "                posteriors.append(log_prior + log_likelihood)\n",
    "\n",
    "            y_pred.append(self.classes[np.argmax(posteriors)])\n",
    "\n",
    "        return np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4949fb19",
   "metadata": {},
   "source": [
    "## Model Training and evluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b5d990b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5115\n",
      "Precision: 0.5433\n",
      "Recall: 0.5115\n",
      "F1-score: 0.5144\n",
      "\n",
      "Confusion Matrix:\n",
      "[[118  26   3   8  15   7  11   2   2   8]\n",
      " [  2 133   2  19   5   5   7  20   4   3]\n",
      " [  4  40  70  42   6   1   1  11  16   9]\n",
      " [ 11  25  11 122   7   2   0   5   6  11]\n",
      " [ 18  28   8   3  86   1  10   7  23  16]\n",
      " [ 12  45   9   3   6  89  14   5  12   5]\n",
      " [ 14  38   2   2   3  13 117   4   6   1]\n",
      " [  6  35   6  12   9   2   2 100  13  15]\n",
      " [ 13  31   6  19  12  17  10   7  77   8]\n",
      " [ 12  21   6  18  10   1   0  15   6 111]]\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNaiveBayes()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1-score: {f1:.4f}\")\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a6cc97",
   "metadata": {},
   "source": [
    "## k_fold for Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f44f675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold accuracy: 0.4995\n",
      "Fold accuracy: 0.5095\n",
      "Fold accuracy: 0.5020\n",
      "Fold accuracy: 0.5270\n",
      "Fold accuracy: 0.5045\n",
      "Mean : 0.5085\n",
      "standard deviation : 0.009823441352194262\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kf_linear = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "cv_scores = []\n",
    "\n",
    "for train_idx, test_idx in kf_linear.split(X):\n",
    "    X_train_fold, X_test_fold = X[train_idx], X[test_idx]\n",
    "    y_train_fold, y_test_fold = y[train_idx], y[test_idx]\n",
    "\n",
    "    model = GaussianNaiveBayes()\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    y_pred = model.predict(X_test_fold)\n",
    "\n",
    "    fold_acc = accuracy_score(y_test_fold, y_pred)\n",
    "    print(f\"Fold accuracy: {fold_acc:.4f}\")\n",
    "    cv_scores.append(fold_acc)\n",
    "\n",
    "print(\"Mean :\",np.mean(cv_scores))\n",
    "print(\"standard deviation :\",np.std(cv_scores))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
